# Sequence Models in TinyML

This repository explores optimizing sequence models like **RNN, LSTM, and GRU** for **TinyML applications**. The goal is to downsize these models while maintaining performance and efficiency.

## ğŸš€ Project Overview <br>
- Compare **RNN, LSTM, and GRU** architectures in terms of accuracy, loss, and inference time.
- Optimize models for **TinyML deployment** using **TensorFlow Lite (TFLite) and ONNX**.
- Evaluate trade-offs between **performance and model size**.

## ğŸ“‚ Repository Structure
```
ğŸ“ Sequence-Models-TinyML/
|â”€â”€SmartPhone Based HAR
    â”‚â”€â”€ ğŸ“‚ Notebooks/           # All ipynb files created in this project
    â”‚â”€â”€ ğŸ“‚ Rawdata/             # Unprocessed raw data from accelerometer and gyroscope  
    â”‚â”€â”€ ğŸ“‚ trained_models/      # Trained models (RNN, LSTM, GRU)  
    â”‚â”€â”€ ğŸ“‚ training_evaluation/ # Training Details of Models in pictorial representation 
    â”‚â”€â”€ ğŸ“‚ training_history/    # Training History of Models saved for future purposes 
    â”‚â”€â”€ ğŸ“‚ usable_raw_data/ # Raw data transformed into trainable format for the project 
    â”‚â”€â”€ ğŸ“ README.md            # This file    
```
As the project progresses, we will:<br>
âœ… Compare RNN, LSTM, and GRU on benchmark datasets.<br>
âœ… Optimize models for low-memory and low-power devices.<br>
âœ… Convert and deploy models using TensorFlow Lite (TFLite) and ONNX.<br>
âœ… Evaluate inference time, accuracy, and model size trade-offs.<br>

âš™ï¸ Current Progress <br>
âœ”ï¸ Implemented baseline# Sequence_Models_TinyML

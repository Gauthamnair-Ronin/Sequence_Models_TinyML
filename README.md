# Sequence Models in TinyML

This repository explores optimizing sequence models like **RNN, LSTM, and GRU** for **TinyML applications**. The goal is to downsize these models while maintaining performance and efficiency.

## 🚀 Project Overview <br>
- Compare **RNN, LSTM, and GRU** architectures in terms of accuracy, loss, and inference time.
- Optimize models for **TinyML deployment** using **TensorFlow Lite (TFLite) and ONNX**.
- Evaluate trade-offs between **performance and model size**.

## 📂 Repository Structure
```
📁 Sequence-Models-TinyML/
|──SmartPhone Based HAR
    │── 📂 Rawdata/           # Unprocessed raw data from accelerometer and gyroscope  
    │── 📂 trained_models/            # Trained models (RNN, LSTM, GRU)  
    │── 📂 notebooks/         # Jupyter Notebooks for experiments  
    │── 📂 scripts/           # Python scripts for training & evaluation  
    │── 📝 README.md          # This file  
    │── 📄 requirements.txt   # Dependencies  
    │── 📄 training_history/  # Saved history of trained models  
```
As the project progresses, we will:<br>
✅ Compare RNN, LSTM, and GRU on benchmark datasets.<br>
✅ Optimize models for low-memory and low-power devices.<br>
✅ Convert and deploy models using TensorFlow Lite (TFLite) and ONNX.<br>
✅ Evaluate inference time, accuracy, and model size trade-offs.<br>

⚙️ Current Progress <br>
✔️ Implemented baseline# Sequence_Models_TinyML
